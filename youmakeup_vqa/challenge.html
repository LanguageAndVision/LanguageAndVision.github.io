
<!DOCTYPE HTML>
<html>
<head>
<title>YouMakeup Video Question Answering Challenge</title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="static/css/main.css" />
</head>
<body>

<!-- Header -->
<header id="header">
  <div class="inner">
    <a href="index.html" class="logo">YouMakeup</a>
    <nav id="nav">
      <a href="index.html">Home</a>
      <a href="challenge.html">Challenge</a>
      <a href="dataset.html">Dataset</a>
      <a href="people.html">People</a>
    </nav>
  </div>
</header>
<a href="#menu" class="navPanelToggle"><span class="fa fa-bars"></span></a>


<!-- Main -->
<section id="main" >
  <div class="inner">
    <header class="major special">
      <h2>Task Description</h2>
    </header>
    <br>
      <h3 style="color:#666699">Image Ordering Sub-Challenge</h3>
        <p>The task is to sort a set of facial images in a video into correct order according to the given step descriptions. 
        The goal of this task is to understand changes of object given a certain action in flexible natural language expression.
        The effects of action descriptions on facial appearances can vary a lot, which not only determined by the textual description, but also depends on the previous state of face appearance.
        Some actions can bring significant facial changes such as "apply red lipsticks on the lips", while some actions only cause subtle differences such as "apply foundation on the face with brush" which can be better detected if being aware of the previous facial appearance.
        Therefore, fine-grained multimodal analysis on visual faces and textual actions is necessary to tackle this task.</p>
        <span class="image fit"><img src="static/img/image_ordering.png" alt="" /></span>
      <h3 style="color:#666699">Step Ordering Sub-Challenge</h3>
        <p>The task is to sort a set of action descriptions into the order of actions performed in the video. 
        It aims at evaluating models' abilities in cross-modal semantic alignments between visual and texts.
        The novelties of the task compared with previous video-text cross-modal retrieval are threefolds.
        Firstly, different actions share similar background contexts, which requires the model to specifically focus on actions and action-related objects instead of correlated but irrelevant contexts.
        Secondly, since different actions can be very similar in visual appearance, the task are more demand on fine-grained discrimination.
        Finally, our task goes beyond singe video-text retrieval and requires long-term temporal action reasoning and textual understanding.</p>
        <span class="image fit"><img src="static/img/step_ordering.png" alt="" /></span>
        <br>
    </div>
</section>


<section id='guideline'>
    <div class="inner">
        <header class="major special">
            <h2>Challenge Guidelines</h2>
        </header>
        <br>
        <h3 style="color:#666699">Dataset Download</h3>
        <p>Please refer to the details at the <a href="dataset.html">Dataset</a> page. The baseline codes and models are released at <a href="">Here</a>.</p>
        <h3 style="color:#666699">Submission</h3>
        <p>The challenge is hosted at the CodaLab. Please go to the <a href="">challenge</a> page to submit your results.</p>
        <h3 style="color:#666699">Evaluation Metrics</h3>
        <p>The two tasks are evaluated by classifiction accuracy.</p>
        <h3 style="color:#666699">Requirements</h3>
        <p>1. Participants should stick to the definition of training, development and test partition in order to have a fair comparison of different approaches.</p>
        <p>2. The Challenge is a team-based contest. Each team can have one or more members, and an individual cannot be a member of multiple teams. </p>
        <br>
        <p>3. Each team can submit at most two trials a day for each sub-challenge on test partition.</p>
        <p>4. At the end of the Challenge, all teams will be ranked based on the evaluation described above. The top teams will receive award certificates.</p>
        <br><br>
        <h3 style="color:#666699">Baseline Paper</h3>
        <p>The paper introducing the YouMakeup VQA Challenge baseline can be viewed <a href="">here</a>.</p>
    </div>
</section>
<br><br><br>


<!-- Scripts -->
<script src="/static/js/jquery.min.js"></script>
<script src="/static/js/skel.min.js"></script>
<script src="/static/js/util.js"></script>
<script src="/static/js/main.js"></script>


</body>
</html>